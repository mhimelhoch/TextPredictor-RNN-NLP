{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "Q0Mn0wxJhWid",
    "outputId": "e5c91a15-52ac-4ed9-fe4d-d40dc43c5003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4Kcp5SghXqd"
   },
   "outputs": [],
   "source": [
    "path = '/content/gdrive/My Drive/linkedin_a.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JZ6CvESghj--"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_s5h-PjlmT0T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kvFakjA-lv1N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116
    },
    "colab_type": "code",
    "id": "5WtiMpzimZYW",
    "outputId": "16b66b12-3032-4ce9-dcc9-a12bff1bd922"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 6889558\n",
      "total chars: 95\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Embedding\n",
    "from keras.layers import LSTM, Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "import h5py\n",
    "import time\n",
    "\n",
    "embeddings_path =  \"/content/gdrive/My Drive/glove.840B.300d-char.txt\"\n",
    "embedding_dim = 300\n",
    "batch_size = 128\n",
    "use_pca = False\n",
    "lr = 0.001\n",
    "lr_decay = 1e-4\n",
    "maxlen = 10\n",
    "consume_less = 2   # 0 for cpu, 2 for gpu\n",
    "\n",
    "text = open(path, errors= 'ignore').read()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VvqKcfYCnhM9",
    "outputId": "27320b18-4d25-4a74-bf6e-0a57c6d82e6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 1377910\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "\n",
    "step = 5\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Fcg22OOzn0h5",
    "outputId": "821315f8-71f2-4fdf-d216-aafa374adda1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen), dtype=np.int)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t] = char_indices[char]\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S8KR0q93n2xv"
   },
   "outputs": [],
   "source": [
    "# test code to sample on 10% for functional model testing\n",
    "\n",
    "def random_subset(X, y, p=0.1):\n",
    "\n",
    "    idx = np.random.randint(X.shape[0], size=int(X.shape[0] * p))\n",
    "    X = X[idx, :]\n",
    "    y = y[idx]\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "T7HwsYmon5Gp",
    "outputId": "35278c1c-d51f-4933-fa1a-d2878208a765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pretrained character embeds...\n"
     ]
    }
   ],
   "source": [
    "print('Processing pretrained character embeds...')\n",
    "embedding_vectors = {}\n",
    "with open(embeddings_path, 'r') as f:\n",
    "    for line in f:\n",
    "        line_split = line.strip().split(\" \")\n",
    "        vec = np.array(line_split[1:], dtype=float)\n",
    "        char = line_split[0]\n",
    "        embedding_vectors[char] = vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IkHsSgZIn7ac"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(chars), 300))\n",
    "#embedding_matrix = np.random.uniform(-1, 1, (len(chars), 300))\n",
    "for char, i in char_indices.items():\n",
    "    #print (\"{}, {}\".format(char, i))\n",
    "    embedding_vector = embedding_vectors.get(char)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_YCt678n-QE"
   },
   "outputs": [],
   "source": [
    "# Use PCA from sklearn to reduce 300D -> 50D\n",
    "if use_pca:\n",
    "    pca = PCA(n_components=embedding_dim)\n",
    "    pca.fit(embedding_matrix)\n",
    "    embedding_matrix_pca = np.array(pca.transform(embedding_matrix))\n",
    "    print (embedding_matrix_pca)\n",
    "    print (embedding_matrix_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "id": "R_1nHoCGoAgg",
    "outputId": "831a528b-9b64-4f34-9223-60f8d62860b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "main_input = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(\n",
    "    len(chars), embedding_dim, input_length=maxlen,\n",
    "    weights=[embedding_matrix_pca] if use_pca else [embedding_matrix])\n",
    "# embedding_layer = Embedding(\n",
    "#     len(chars), embedding_dim, input_length=maxlen)\n",
    "embedded = embedding_layer(main_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "YOQHub_2oCDb",
    "outputId": "16bea391-b4db-4f72-9a4b-5dd094dcbf2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RNN Layer\n",
    "rnn = LSTM(256, implementation=consume_less)(embedded)\n",
    "\n",
    "aux_output = Dense(len(chars))(rnn)\n",
    "aux_output = Activation('softmax', name='aux_out')(aux_output)\n",
    "\n",
    "# Hidden Layers\n",
    "hidden_1 = Dense(512, use_bias=False)(rnn)\n",
    "hidden_1 = BatchNormalization()(hidden_1)\n",
    "hidden_1 = Activation('relu')(hidden_1)\n",
    "\n",
    "hidden_2 = Dense(256, use_bias=False)(hidden_1)\n",
    "hidden_2 = BatchNormalization()(hidden_2)\n",
    "hidden_2 = Activation('relu')(hidden_2)\n",
    "\n",
    "main_output = Dense(len(chars))(hidden_2)\n",
    "main_output = Activation('softmax', name='main_out')(main_output)\n",
    "\n",
    "model = Model(inputs=main_input, outputs=[main_output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "colab_type": "code",
    "id": "vN2QK91LoGV-",
    "outputId": "384ab50d-485a-4783-9cdf-f2170671b926"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 10, 300)      28500       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 256)          570368      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          131072      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512)          2048        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          131072      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 95)           24415       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 95)           24415       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "main_out (Activation)           (None, 95)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "aux_out (Activation)            (None, 95)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 912,914\n",
      "Trainable params: 911,378\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr=lr, decay=lr_decay)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, metrics = ['accuracy'], loss_weights=[1., 0.2])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6sd8PcqoIkx"
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds + 1e-6) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xUztLnL7oObF"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('output'):\n",
    "    os.makedirs('output')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "owPieYBHoQn5",
    "outputId": "bec0aa08-6058-4e72-b8c2-110969c0381c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('output/log.csv', 'w')\n",
    "log_writer = csv.writer(f)\n",
    "log_writer.writerow(['iteration', 'batch', 'batch_loss',\n",
    "                     'epoch_loss', 'elapsed_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OazHsMIvoScy"
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(\n",
    "    \"output/model.hdf5\", monitor='main_out_loss', save_best_only=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bn6RDa80oVN0"
   },
   "outputs": [],
   "source": [
    "class BatchLossLogger(Callback):\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('main_out_loss'))\n",
    "        if batch % 50 == 0:\n",
    "            log_writer.writerow([iteration, batch,\n",
    "                                 logs.get('main_out_loss'),\n",
    "                                 np.mean(self.losses),\n",
    "                                 round(time.time() - start_time, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kXEmBHjSoXYu",
    "outputId": "f7535e9e-19d5-499f-a8dc-bc4d340ed628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/1\n",
      "1377910/1377910 [==============================] - 255s 185us/step - loss: 3.3925 - main_out_loss: 2.8254 - aux_out_loss: 2.8354 - main_out_acc: 0.1863 - aux_out_acc: 0.1860\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      "1377910/1377910 [==============================] - 248s 180us/step - loss: 3.2941 - main_out_loss: 2.7435 - aux_out_loss: 2.7527 - main_out_acc: 0.2054 - aux_out_acc: 0.2040\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/1\n",
      "1377910/1377910 [==============================] - 246s 179us/step - loss: 3.2532 - main_out_loss: 2.7081 - aux_out_loss: 2.7258 - main_out_acc: 0.2145 - aux_out_acc: 0.2114\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/1\n",
      "1377910/1377910 [==============================] - 246s 179us/step - loss: 3.2250 - main_out_loss: 2.6832 - aux_out_loss: 2.7090 - main_out_acc: 0.2208 - aux_out_acc: 0.2158\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/1\n",
      "1377910/1377910 [==============================] - 255s 185us/step - loss: 3.2033 - main_out_loss: 2.6639 - aux_out_loss: 2.6974 - main_out_acc: 0.2256 - aux_out_acc: 0.2188\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/1\n",
      "1377910/1377910 [==============================] - 253s 184us/step - loss: 3.1859 - main_out_loss: 2.6482 - aux_out_loss: 2.6887 - main_out_acc: 0.2294 - aux_out_acc: 0.2212\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/1\n",
      "1377910/1377910 [==============================] - 247s 180us/step - loss: 3.1706 - main_out_loss: 2.6342 - aux_out_loss: 2.6817 - main_out_acc: 0.2330 - aux_out_acc: 0.2231\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/1\n",
      "1377910/1377910 [==============================] - 247s 180us/step - loss: 3.1576 - main_out_loss: 2.6223 - aux_out_loss: 2.6763 - main_out_acc: 0.2361 - aux_out_acc: 0.2248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/1\n",
      "1377910/1377910 [==============================] - 246s 178us/step - loss: 3.1461 - main_out_loss: 2.6117 - aux_out_loss: 2.6718 - main_out_acc: 0.2388 - aux_out_acc: 0.2259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/1\n",
      "1377910/1377910 [==============================] - 246s 178us/step - loss: 3.1358 - main_out_loss: 2.6022 - aux_out_loss: 2.6679 - main_out_acc: 0.2408 - aux_out_acc: 0.2273\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/1\n",
      "1377910/1377910 [==============================] - 244s 177us/step - loss: 3.1263 - main_out_loss: 2.5934 - aux_out_loss: 2.6647 - main_out_acc: 0.2430 - aux_out_acc: 0.2281\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/1\n",
      "1377910/1377910 [==============================] - 251s 182us/step - loss: 3.1175 - main_out_loss: 2.5851 - aux_out_loss: 2.6619 - main_out_acc: 0.2449 - aux_out_acc: 0.2286\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/1\n",
      "1377910/1377910 [==============================] - 257s 187us/step - loss: 3.1099 - main_out_loss: 2.5780 - aux_out_loss: 2.6594 - main_out_acc: 0.2469 - aux_out_acc: 0.2295\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/1\n",
      "1377910/1377910 [==============================] - 261s 189us/step - loss: 3.1027 - main_out_loss: 2.5713 - aux_out_loss: 2.6573 - main_out_acc: 0.2485 - aux_out_acc: 0.2301\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/1\n",
      "1377910/1377910 [==============================] - 268s 195us/step - loss: 3.0961 - main_out_loss: 2.5650 - aux_out_loss: 2.6554 - main_out_acc: 0.2502 - aux_out_acc: 0.2305\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/1\n",
      "1377910/1377910 [==============================] - 257s 187us/step - loss: 3.0898 - main_out_loss: 2.5591 - aux_out_loss: 2.6537 - main_out_acc: 0.2517 - aux_out_acc: 0.2310\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/1\n",
      "1377910/1377910 [==============================] - 255s 185us/step - loss: 3.0840 - main_out_loss: 2.5536 - aux_out_loss: 2.6521 - main_out_acc: 0.2528 - aux_out_acc: 0.2313\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/1\n",
      "1377910/1377910 [==============================] - 262s 190us/step - loss: 3.0785 - main_out_loss: 2.5484 - aux_out_loss: 2.6508 - main_out_acc: 0.2542 - aux_out_acc: 0.2317\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/1\n",
      "1377910/1377910 [==============================] - 270s 196us/step - loss: 3.0734 - main_out_loss: 2.5435 - aux_out_loss: 2.6496 - main_out_acc: 0.2554 - aux_out_acc: 0.2319\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for iteration in range(1, 20):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "\n",
    "    logger = BatchLossLogger()\n",
    "    # X_train, y_train = random_subset(X, y)\n",
    "    # history = model.fit(X_train, [y_train, y_train], batch_size=batch_size,\n",
    "    #                     epochs=1, callbacks=[logger, checkpointer])\n",
    "    history = model.fit(X, [y, y], batch_size=batch_size,\n",
    "                        epochs=1, callbacks=[logger, checkpointer])\n",
    "    loss = str(history.history['main_out_loss'][-1]).replace(\".\", \"_\")\n",
    "\n",
    "    f2 = open('output/iter-{:02}-{:.6}.txt'.format(iteration, loss), 'w')\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "   \n",
    "    f2.close()\n",
    "\n",
    "    # Write embeddings for current characters to file\n",
    "    # The second layer has the embeddings.\n",
    "\n",
    "    embedding_weights = model.layers[1].get_weights()[0]\n",
    "    f3 = open('output/char-embeddings.txt', 'w')\n",
    "    for char in char_indices:\n",
    "        if ord(char) < 128:\n",
    "            embed_vector = embedding_weights[char_indices[char], :]\n",
    "            f3.write(char + \" \" + \" \".join(str(x)\n",
    "                                           for x in embed_vector) + \"\\n\")\n",
    "    f3.close()\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "ZIwKiUT9okUh",
    "outputId": "03898e9a-7a04-4407-8230-a13144d48c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- diversity: 1.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-033d1435fb9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----- diversity:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m        \u001b[0mf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----- diversity:'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiversity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m        \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f2' is not defined"
     ]
    }
   ],
   "source": [
    " for diversity in [1.0]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "        f2.write('----- diversity:' + ' ' + str(diversity) + '\\n')\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        f2.write('----- Generating with seed: \"' + sentence + '\"' + '\\n---\\n')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(10):\n",
    "            x = np.zeros((1, maxlen), dtype=np.int)\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t] = char_indices[char]\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0][0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        f2.write(generated + '\\n')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1eWdQgnfj2mL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "EmbeddingsModel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
