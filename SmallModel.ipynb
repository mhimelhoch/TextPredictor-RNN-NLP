{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SmallModel.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrLMHg8oCl-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "5bf1e3ae-3908-467d-f8bb-ad62e040d875"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive') "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ2ZPAIaCqw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/gdrive/My Drive/linkedin_a.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKRQIf2wCyIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = open(path, errors = 'ignore').read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoKwGxzLDBAN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da978030-30de-4c24-f43e-6b0f47cf3fb5"
      },
      "source": [
        "print('corpus length:', len(text))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus length: 6889558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4NKisl5DCIZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "24e1b034-933a-4803-db58-958cd0da560a"
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Activation, Embedding\n",
        "from keras.layers import LSTM, Input\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from sklearn.decomposition import PCA\n",
        "from keras.utils import plot_model\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import csv\n",
        "import os\n",
        "import h5py\n",
        "import time\n",
        "\n",
        "embeddings_path =  \"/content/gdrive/My Drive/glove.840B.300d-char.txt\"\n",
        "embedding_dim = 300\n",
        "batch_size = 128\n",
        "use_pca = False\n",
        "lr = 0.001\n",
        "lr_decay = 1e-4\n",
        "maxlen = 10\n",
        "consume_less = 2   # 0 for cpu, 2 for gpu\n",
        "\n",
        "text = open(path, errors= 'ignore').read()\n",
        "print('corpus length:', len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "corpus length: 6889558\n",
            "total chars: 95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4D_CO81DMC9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "123fd762-2dc2-4c58-d93d-d2b186da494f"
      },
      "source": [
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "\n",
        "step = 6\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 1148258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Uc0AXYHDOhl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc5f81af-89c2-4801-c492-3e9ed9929cfc"
      },
      "source": [
        "print('Vectorization...')\n",
        "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.int)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzg0PFhWDVAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test code to sample on 10% for functional model testing\n",
        "\n",
        "def random_subset(X, y, p=0.1):\n",
        "\n",
        "    idx = np.random.randint(X.shape[0], size=int(X.shape[0] * p))\n",
        "    X = X[idx, :]\n",
        "    y = y[idx]\n",
        "    return (X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AbS2iEpDXCN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "edb77ea6-7f1b-4732-b47b-cc9cf953da22"
      },
      "source": [
        "print('Processing pretrained character embeds...')\n",
        "embedding_vectors = {}\n",
        "with open(embeddings_path, 'r') as f:\n",
        "    for line in f:\n",
        "        line_split = line.strip().split(\" \")\n",
        "        vec = np.array(line_split[1:], dtype=float)\n",
        "        char = line_split[0]\n",
        "        embedding_vectors[char] = vec\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing pretrained character embeds...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSmpl-f3DYer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((len(chars), 300))\n",
        "#embedding_matrix = np.random.uniform(-1, 1, (len(chars), 300))\n",
        "for char, i in char_indices.items():\n",
        "    #print (\"{}, {}\".format(char, i))\n",
        "    embedding_vector = embedding_vectors.get(char)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcpp5MM3DaKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use PCA from sklearn to reduce 300D -> 50D\n",
        "if use_pca:\n",
        "    pca = PCA(n_components=embedding_dim)\n",
        "    pca.fit(embedding_matrix)\n",
        "    embedding_matrix_pca = np.array(pca.transform(embedding_matrix))\n",
        "    print (embedding_matrix_pca)\n",
        "    print (embedding_matrix_pca.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhQbnIRTDcEL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "7b04db8e-db2d-4348-acc1-1f5b9b392085"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.optimizers import RMSprop\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape = (10, len(chars))))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "optimizer = RMSprop(lr = 0.01)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 128)               114688    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 95)                12255     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 95)                0         \n",
            "=================================================================\n",
            "Total params: 126,943\n",
            "Trainable params: 126,943\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO4IVDKcENw9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "outputId": "54e4d9f9-db6f-4552-f01c-1d914dc6fdbc"
      },
      "source": [
        "model.fit(X, y, batch_size = 128, epochs = 5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "1148258/1148258 [==============================] - 194s 169us/step - loss: 2.8387 - acc: 0.1874\n",
            "Epoch 2/5\n",
            "1148258/1148258 [==============================] - 189s 164us/step - loss: 2.8120 - acc: 0.1960\n",
            "Epoch 3/5\n",
            "1148258/1148258 [==============================] - 189s 165us/step - loss: 2.8164 - acc: 0.1965\n",
            "Epoch 4/5\n",
            "1148258/1148258 [==============================] - 187s 163us/step - loss: 2.8219 - acc: 0.1965\n",
            "Epoch 5/5\n",
            "1148258/1148258 [==============================] - 186s 162us/step - loss: 2.8322 - acc: 0.1956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fabb3c3e710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t2HDp9yElHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}